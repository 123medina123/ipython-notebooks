{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Linear Regression using Theano"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the required modules\n",
      "from theano import tensor as T\n",
      "from theano import function\n",
      "from theano import pp\n",
      "from theano import Param\n",
      "from theano import grad\n",
      "from theano import shared\n",
      "import numpy as np\n",
      "\n",
      "# Define the symbolic Variables\n",
      "X, y, W = T.matrices('training-set', 'testing-set', 'weights')\n",
      "m, a = T.scalars('no-of-samples', 'learning-rate')\n",
      "\n",
      "# Define the cost function and the gradient\n",
      "cost_fn = (((T.dot(X, W) - y)**2)/(2. * m)).sum()\n",
      "grad_fn = (T.dot(T.transpose(X), T.dot(X, W) - y))/(m)\n",
      "updated_wts = W - a * grad_fn\n",
      "\n",
      "# Compile the Theano functions\n",
      "cost = function([X, y, W, m], cost_fn)\n",
      "new_wts = function([X, y, W, m, a], updated_wts)\n",
      "\n",
      "# Prepare the dataset\n",
      "X_val = np.array([[1],[4],[6],[8],[10],[12],[14]])\n",
      "bias = np.ones((X_val.shape[0], 1))\n",
      "X_val = np.hstack((X_val, bias))\n",
      "y_val = np.array([[2], [3], [4], [5], [6], [7], [8]])\n",
      "m_val = X_val.shape[0]\n",
      "W_val = np.transpose(np.array([[0], [0]])).reshape((X_val[0].shape[0],1))\n",
      "a_val = .001\n",
      "iterations = 10000\n",
      "\n",
      "# Calculate the cost function and gradient descent \n",
      "# and update the weights\n",
      "for i in xrange(iterations):\n",
      "    cst = cost(X_val, y_val, W_val, m_val)\n",
      "    W_val = new_wts(X_val, y_val, W_val, m_val, a_val)    \n",
      "  \n",
      "# Perform the perdictions\n",
      "X_test = np.array([[8, 1], [9, 1], [10, 1]])\n",
      "y_test = np.array([[5], [5.5], [6]])\n",
      "y_pred = np.dot(X_test, W_val)\n",
      "for X_test_c , y_test_c, y_pred_c in zip(X_test, y_test, y_pred):\n",
      "    print \"Sample {} Actual Value = {} Predicted Value = {} \".format(X_test_c, y_test_c, y_pred_c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sample [8 1] Actual Value = [ 5.] Predicted Value = [ 5.03978118] \n",
        "Sample [9 1] Actual Value = [ 5.5] Predicted Value = [ 5.52552955] \n",
        "Sample [10  1] Actual Value = [ 6.] Predicted Value = [ 6.01127793] \n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Corresponding Class with convenient `fit`, `predict` interfaces as in case of sklearn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LinearRegression:\n",
      "    '''\n",
      "    This class performs linear regression.\n",
      "    '''\n",
      "    def __init__(self, alpha=0.001, iterations=1000):\n",
      "        '''\n",
      "        1. alpha is the learning rate. \n",
      "            The default value of alpha is 0.001.\n",
      "        2. iterations is the number of times the weights will be updated.\n",
      "            The default value is 1000\n",
      "        '''\n",
      "        # Set the learning rate\n",
      "        self.alpha = alpha\n",
      "        # Set the number of iterations\n",
      "        self.iterations = iterations\n",
      "        \n",
      "        # Define the symbolic Variables\n",
      "        X, y, W = T.matrices('training-set', 'testing-set', 'weights')\n",
      "        m, a = T.scalars('no-of-samples', 'learning-rate')\n",
      "        \n",
      "        # Define the cost function and the gradient functions\n",
      "        cost_fn = (((T.dot(X, W) - y)**2)/(2. * m)).sum()\n",
      "        grad_fn = (T.dot(T.transpose(X), T.dot(X, W) - y))/(m)\n",
      "        updated_wts = W - a * grad_fn\n",
      "        \n",
      "        # Compile the Theano functions\n",
      "        self.cost = function([X, y, W, m], cost_fn)\n",
      "        self.new_wts = function([X, y, W, m, a], updated_wts)\n",
      "        self.pred = function([X, W], T.dot(X, W))\n",
      "        \n",
      "    def fit(self, X, y):\n",
      "        '''\n",
      "        The fit member function is used to train the classifier.\n",
      "        1. X is array-like data vector\n",
      "        2. y is array-like target vector\n",
      "        '''\n",
      "        # Add the bias feature to the data samples\n",
      "        bias = np.ones((X.shape[0], 1))\n",
      "        X = np.hstack((X, bias))\n",
      "        \n",
      "        # m is the number of data samples used\n",
      "        m = X.shape[0]\n",
      "        \n",
      "        # Initialize all weights to 0\n",
      "        self.W = np.transpose(np.array([[0], [0]])).reshape((X[0].shape[0],1))\n",
      "        \n",
      "        # Iterate and update the cost function and the weights\n",
      "        for i in xrange(self.iterations):\n",
      "            cst = self.cost(X, y, self.W, m)\n",
      "            self.W = self.new_wts(X, y, self.W, m, self.alpha)    \n",
      "            \n",
      "    def predict(self, X):\n",
      "        '''\n",
      "        This is function to predict target. \n",
      "        \n",
      "        1. X is array-like data vector whose target vector is predicted\n",
      "        '''\n",
      "        # Return the predicted target values\n",
      "        return self.pred(X, self.W)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Preparea a small dataset\n",
      "# The dataset is a generated\n",
      "# using the function of y = X/2 + 1\n",
      "X_train = np.array([[1],[4],[6],[8],[10],[12],[14]])\n",
      "y_train = np.array([[2], [3], [4], [5], [6], [7], [8]])\n",
      "X_test = np.array([[8, 1], [9, 1], [10, 1]])\n",
      "y_test = np.array([[5], [5.5], [6]])\n",
      "\n",
      "# Create the classifier object\n",
      "clf = LinearRegression()\n",
      "# Perform the training\n",
      "clf.fit(X_train, y_train)\n",
      "# Predict using the classifier\n",
      "y_pred = clf.predict(X_test)\n",
      "\n",
      "# Display the results\n",
      "for X_test_c , y_test_c, y_pred_c in zip(X_test, y_test, y_pred):\n",
      "    print \"Sample {} Actual Value = {} Predicted Value = {} \".format(X_test_c, y_test_c, y_pred_c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sample [8 1] Actual Value = [ 5.] Predicted Value = [ 4.86303075] \n",
        "Sample [9 1] Actual Value = [ 5.5] Predicted Value = [ 5.43298531] \n",
        "Sample [10  1] Actual Value = [ 6.] Predicted Value = [ 6.00293987] \n"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}